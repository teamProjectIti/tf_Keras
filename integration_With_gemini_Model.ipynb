{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3uawmcZ99tan0lOzCbS07",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teamProjectIti/tf_Keras/blob/main/integration_With_gemini_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Manually set the Google API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "\n",
        "# Configure Google Generative AI\n",
        "try:\n",
        "    google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
        "\n",
        "    if google_api_key:\n",
        "        print(f\"✅ Google API Key loaded: {google_api_key[:8]}... (hidden for security)\")\n",
        "        google.generativeai.configure(api_key=google_api_key)\n",
        "        print(\"✅ Google Generative AI client configured successfully.\")\n",
        "    else:\n",
        "        print(\"❌ Google API Key not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Error configuring Google Generative AI: {e}\")\n"
      ],
      "metadata": {
        "id": "E0vNREeFBPRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google.generativeai.configure()\n"
      ],
      "metadata": {
        "id": "emvFdKJsBmBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"عاوز نكته مصريه\"\n",
        "user_prompt = \"قل نكتة خفيفة الظل لجمهور من عامه الناس\"\n",
        "prompts = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "  ]\n"
      ],
      "metadata": {
        "id": "Ngzxc8wFKZBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini = google.generativeai.GenerativeModel(\n",
        "    model_name='gemini-2.0-flash',\n",
        "    system_instruction=system_message\n",
        ")\n",
        "response = gemini.generate_content(user_prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "FmiESdr_KchI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr # oh yeah!\n",
        "def message_gemini(prompt):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=messages,\n",
        "    )\n",
        "    return completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "Z5LRm_UxM_4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Authenticate if needed (use your API key if required)\n",
        "# genai.configure(api_key=\"YOUR_API_KEY\")  # Uncomment and set your key if needed\n",
        "\n",
        "# Gemini function\n",
        "def message_gemini(prompt: str, system_message: str = \"عاوز نكته مصريه\") -> str:\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name='gemini-1.5-flash',\n",
        "        system_instruction=system_message\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "# Example usage\n",
        "print(message_gemini(\"قل نكتة خفيفة الظل لجمهور من عامة الناس\"))\n"
      ],
      "metadata": {
        "id": "sWX6kPWqp4b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message_gemini(\"من هو اشهر لاعب كوره قدم\"))\n"
      ],
      "metadata": {
        "id": "z4ZsO3_9qEBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_gemini(\"What is today's date?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fj_GD5Jqmu-",
        "outputId": "3f78c19d-4843-41da-efa9-a64a6bf46f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 626, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 350, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2235, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1746, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 917, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-23-505725200.py\", line 12, in message_gemini\n",
            "    response = model.generate_content(prompt)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n",
            "    response = self._client.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 835, in generate_content\n",
            "    response = rpc(\n",
            "               ^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\", line 294, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\", line 156, in retry_target\n",
            "    next_sleep = _retry_error_helper(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\", line 214, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\", line 147, in retry_target\n",
            "    result = target()\n",
            "             ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\", line 130, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n",
            "    return callable_(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 1148, in __call__\n",
            "    response = GenerativeServiceRestTransport._GenerateContent._get_response(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\", line 1048, in _get_response\n",
            "    response = getattr(session, method)(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 637, in post\n",
            "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/auth/transport/requests.py\", line 537, in request\n",
            "    response = super(AuthorizedSession, self).request(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 713, in send\n",
            "    raise ReadTimeout(e, request=request)\n",
            "requests.exceptions.ReadTimeout: HTTPConnectionPool(host='localhost', port=34613): Read timed out. (read timeout=600.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shout(text):\n",
        "    print(f\"Shout has been called with input {text}\")\n",
        "    return text.upper()"
      ],
      "metadata": {
        "id": "ip2Nmb9lqu_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shout(\"hello\")\n"
      ],
      "metadata": {
        "id": "WgqqD9vxq5le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()\n"
      ],
      "metadata": {
        "id": "C9EcMjXwq6nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)\n"
      ],
      "metadata": {
        "id": "hQVuzwRtq-dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)\n"
      ],
      "metadata": {
        "id": "inkKSjyvrRND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "force_dark_mode = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "    if (url.searchParams.get('__theme') !== 'dark') {\n",
        "        url.searchParams.set('__theme', 'dark');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()\n"
      ],
      "metadata": {
        "id": "EhpYZff9rocX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inputs and Outputs\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=shout,\n",
        "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
        "    outputs=[gr.Textbox(label=\"Response:\", lines=8)],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ],
      "metadata": {
        "id": "9stO4t6Ir1mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And now - changing the function from \"shout\" to \"message_gpt\"\n",
        "\n",
        "view = gr.Interface(\n",
        "    fn=message_gemini,\n",
        "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
        "    outputs=[gr.Textbox(label=\"Response:\", lines=8)],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "\n",
        "# Start the Gradio app\n",
        "view.launch()"
      ],
      "metadata": {
        "id": "-O-H19yUsQFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3g56AeZslpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}